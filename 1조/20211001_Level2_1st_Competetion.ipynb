{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "20211001_Level2_1st_Competetion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:psd] *",
      "language": "python",
      "name": "conda-env-psd-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pseudope/2021_F_Level2/blob/main/Projects/1%EC%A1%B0/20211001_Level2_1st_Competetion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a99mpdQIEY_7"
      },
      "source": [
        "# Level 2 1<sup>st</sup> Competetion\n",
        "\n",
        "1조 competetion 자료"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:47.922405Z",
          "iopub.status.busy": "2021-10-01T08:49:47.922204Z",
          "iopub.status.idle": "2021-10-01T08:49:50.955500Z",
          "shell.execute_reply": "2021-10-01T08:49:50.954832Z",
          "shell.execute_reply.started": "2021-10-01T08:49:47.922380Z"
        },
        "tags": [],
        "id": "amL_GiPREY__"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pprint import pprint\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from gensim.models.fasttext import FastText as FT_gensim\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.flow as nafc\n",
        "from nlpaug.util import Action\n",
        "\n",
        "import nltk\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical, Sequence\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.experimental import CosineDecayRestarts\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "from tensorflow_addons.optimizers import RectifiedAdam as RAdam\n",
        "from tensorflow_addons.optimizers import AdamW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SScViDI_SdN5",
        "tags": []
      },
      "source": [
        "# 참고 자료 및 출처"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joMIMS7YSfZT"
      },
      "source": [
        "데이터셋 논문: https://arxiv.org/pdf/1811.04231.pdf <br>\n",
        "GitHub: https://github.com/warnikchow/3i4k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0dVfVFAS4sf"
      },
      "source": [
        "Pretrained Data Citation\n",
        "\n",
        "@article{cho2018real, <br>\n",
        "\ttitle={Real-time Automatic Word Segmentation for User-generated Text}, <br>\n",
        "\tauthor={Cho, Won Ik and Cheon, Sung Jun and Kang, Woo Hyun and Kim, Ji Won and Kim, Nam Soo}, <br>\n",
        "\tjournal={arXiv preprint arXiv:1810.13113}, <br>\n",
        "\tyear={2018} <br>\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLTslZgWTGw5"
      },
      "source": [
        "Dataset, Guideline Citation\n",
        "\n",
        "@article{cho2018speech, <br>\n",
        "\ttitle={Speech Intention Understanding in a Head-final Language: A Disambiguation Utilizing Intonation-dependency}, <br>\n",
        "\tauthor={Cho, Won Ik and Lee, Hyeon Seung and Yoon, Ji Won and Kim, Seok Min and Kim, Nam Soo}, <br>\n",
        "\tjournal={arXiv preprint arXiv:1811.04231}, <br>\n",
        "\tyear={2018} <br>\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCqfDhDbVLtP"
      },
      "source": [
        "# Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:50.957275Z",
          "iopub.status.busy": "2021-10-01T08:49:50.957051Z",
          "iopub.status.idle": "2021-10-01T08:49:50.960081Z",
          "shell.execute_reply": "2021-10-01T08:49:50.959408Z",
          "shell.execute_reply.started": "2021-10-01T08:49:50.957249Z"
        },
        "id": "1G7ETfXomgtb",
        "tags": []
      },
      "source": [
        "# !wget https://raw.githubusercontent.com/warnikchow/3i4k/master/data/train_val_test/fci_train_val.txt\n",
        "# !wget https://raw.githubusercontent.com/warnikchow/3i4k/master/data/train_val_test/fci_test.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:50.961114Z",
          "iopub.status.busy": "2021-10-01T08:49:50.960923Z",
          "iopub.status.idle": "2021-10-01T08:49:50.969856Z",
          "shell.execute_reply": "2021-10-01T08:49:50.969272Z",
          "shell.execute_reply.started": "2021-10-01T08:49:50.961092Z"
        },
        "id": "knkRCBZJicn0",
        "tags": []
      },
      "source": [
        "def read_data(filename):\n",
        "\n",
        "    with open(filename, \"r\", encoding=\"UTF8\") as f:\n",
        "        data = [line.split(\"\\t\") for line in f.read().splitlines()]\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:50.970834Z",
          "iopub.status.busy": "2021-10-01T08:49:50.970648Z",
          "iopub.status.idle": "2021-10-01T08:49:51.198249Z",
          "shell.execute_reply": "2021-10-01T08:49:51.197586Z",
          "shell.execute_reply.started": "2021-10-01T08:49:50.970812Z"
        },
        "id": "NQQPDtBTijll",
        "tags": []
      },
      "source": [
        "train_data = read_data(\"/home/ubuntu/pseudope/Level 2/competition/fci_train_val.txt\")\n",
        "X_train_data = [t[1] for t in train_data]\n",
        "y_train_data = [int(t[0]) for t in train_data]\n",
        "\n",
        "test_data = read_data(\"/home/ubuntu/pseudope/Level 2/competition/fci_test.txt\")\n",
        "X_test_data = [t[1] for t in test_data]\n",
        "y_test_data = [int(t[0]) for t in test_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:51.199409Z",
          "iopub.status.busy": "2021-10-01T08:49:51.199196Z",
          "iopub.status.idle": "2021-10-01T08:49:51.204304Z",
          "shell.execute_reply": "2021-10-01T08:49:51.203589Z",
          "shell.execute_reply.started": "2021-10-01T08:49:51.199384Z"
        },
        "id": "0aZkljSUijcI",
        "tags": [],
        "outputId": "9bb59b3e-8251-4c75-9bc3-8de01dd72294"
      },
      "source": [
        "print(len(X_train_data))\n",
        "print(len(y_train_data))\n",
        "print(len(X_test_data))\n",
        "print(len(y_test_data))\n",
        "\n",
        "print(X_train_data[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55134\n",
            "55134\n",
            "6121\n",
            "6121\n",
            "['만화', '이치가', '약', '그사이', '짜긴', '혜택', '지출', '어젯밤', '승진', '꼬마']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "S5_csCO3EZAL"
      },
      "source": [
        "## Weight Correction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbWtxL6zEZAM"
      },
      "source": [
        "> 마땅한 방법이 떠오르지 않아서 하드코딩 했는데, 더 나은 방법이 있을지?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:51.205371Z",
          "iopub.status.busy": "2021-10-01T08:49:51.205176Z",
          "iopub.status.idle": "2021-10-01T08:49:51.222470Z",
          "shell.execute_reply": "2021-10-01T08:49:51.221870Z",
          "shell.execute_reply.started": "2021-10-01T08:49:51.205348Z"
        },
        "tags": [],
        "id": "bFQh8YfrEZAM",
        "outputId": "bf8ff632-14e0-40bc-8d59-5f2ab80d1d15"
      },
      "source": [
        "zero_c = 0\n",
        "one_c = 0\n",
        "two_c = 0\n",
        "three_c = 0\n",
        "four_c = 0\n",
        "five_c = 0\n",
        "six_c = 0\n",
        "\n",
        "for number in y_train_data:\n",
        "\n",
        "    if number == 0:\n",
        "         zero_c += 1\n",
        "    elif number == 1:\n",
        "        one_c += 1\n",
        "    elif number == 2:\n",
        "        two_c += 1\n",
        "    elif number == 3:\n",
        "        three_c += 1\n",
        "    elif number == 4:\n",
        "        four_c += 1\n",
        "    elif number == 5:\n",
        "        five_c += 1\n",
        "    elif number == 6:\n",
        "        six_c += 1\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "weight_list = [zero_c, one_c, two_c, three_c, four_c, five_c, six_c]\n",
        "\n",
        "print(weight_list)\n",
        "print(zero_c + one_c + two_c + three_c + four_c + five_c + six_c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5409, 16470, 16083, 11672, 1571, 979, 2950]\n",
            "55134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:51.224405Z",
          "iopub.status.busy": "2021-10-01T08:49:51.224213Z",
          "iopub.status.idle": "2021-10-01T08:49:51.229921Z",
          "shell.execute_reply": "2021-10-01T08:49:51.229419Z",
          "shell.execute_reply.started": "2021-10-01T08:49:51.224382Z"
        },
        "tags": [],
        "id": "tPe5WwNzEZAN",
        "outputId": "94d4fac4-2255-44de-e2c9-e2baace6736e"
      },
      "source": [
        "class_weight = {}\n",
        "\n",
        "for i in range(len(weight_list)):\n",
        "    \n",
        "    foo = len(X_train_data) / ((len(weight_list)) * weight_list[i]) ** 1.125\n",
        "    \n",
        "    print((weight_list[i]))\n",
        "    print(foo)\n",
        "\n",
        "    if foo > 1:\n",
        "        class_weight[i] = foo\n",
        "    else:\n",
        "        class_weight[i] = 1.0\n",
        "\n",
        "print(class_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5409\n",
            "0.3898769884613462\n",
            "16470\n",
            "0.11140480116078282\n",
            "16083\n",
            "0.11442508987246718\n",
            "11672\n",
            "0.1641140519020199\n",
            "1571\n",
            "1.5667005602313935\n",
            "979\n",
            "2.667188307502247\n",
            "2950\n",
            "0.77114214460766\n",
            "{0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.5667005602313935, 5: 2.667188307502247, 6: 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDhfrwbshE4g"
      },
      "source": [
        "# Pretrained Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7uS7rYdhGjb"
      },
      "source": [
        "아래의 사이트에서 pretrained된 100차원 fastText data를 제공하고 있습니다. 원하실 경우 사용하셔도 좋습니다.\n",
        "\n",
        "https://drive.google.com/file/d/1jHbjOcnaLourFzNuP47yGQVhBTq6Wgor/view\n",
        "\n",
        "* Download this and unzip THE .BIN FILE in the NEW FOLDER named 'vectors'.\n",
        "* This can be replaced with whatever model the user employs, but it requires an additional training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T07:52:14.856178Z",
          "iopub.status.busy": "2021-10-01T07:52:14.855854Z",
          "iopub.status.idle": "2021-10-01T07:52:14.860450Z",
          "shell.execute_reply": "2021-10-01T07:52:14.859652Z",
          "shell.execute_reply.started": "2021-10-01T07:52:14.856150Z"
        },
        "id": "3ckMd-n4EZAO"
      },
      "source": [
        "> Preprocessing이 모두 끝난 뒤에 불러오겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKLSdOCbEZAP"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:51.231291Z",
          "iopub.status.busy": "2021-10-01T08:49:51.231100Z",
          "iopub.status.idle": "2021-10-01T08:49:51.236438Z",
          "shell.execute_reply": "2021-10-01T08:49:51.235774Z",
          "shell.execute_reply.started": "2021-10-01T08:49:51.231268Z"
        },
        "tags": [],
        "id": "Kc00MNjfEZAP",
        "outputId": "3390c1cc-ff85-40fa-9d11-9fc263d87b91"
      },
      "source": [
        "text = \"학교 축제 대신 학회에 참여하다니\"\n",
        "\n",
        "aug = naw.RandomWordAug(action=\"swap\")\n",
        "\n",
        "augmented_text = aug.augment(text)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Text:\")\n",
        "print(augmented_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:\n",
            "학교 축제 대신 학회에 참여하다니\n",
            "Augmented Text:\n",
            "학교 축제 대신 참여하다니 학회에\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:51.237352Z",
          "iopub.status.busy": "2021-10-01T08:49:51.237168Z",
          "iopub.status.idle": "2021-10-01T08:49:51.241234Z",
          "shell.execute_reply": "2021-10-01T08:49:51.240628Z",
          "shell.execute_reply.started": "2021-10-01T08:49:51.237330Z"
        },
        "tags": [],
        "id": "x2VNJfmrEZAP",
        "outputId": "4de419a6-4f7c-4069-9a17-91e363050fbd"
      },
      "source": [
        "aug = naw.RandomWordAug()\n",
        "augmented_text = aug.augment(text)\n",
        "\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Text:\")\n",
        "print(augmented_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:\n",
            "학교 축제 대신 학회에 참여하다니\n",
            "Augmented Text:\n",
            "축제 대신 학회에 참여하다니\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:51.242059Z",
          "iopub.status.busy": "2021-10-01T08:49:51.241877Z",
          "iopub.status.idle": "2021-10-01T08:49:58.122824Z",
          "shell.execute_reply": "2021-10-01T08:49:58.122188Z",
          "shell.execute_reply.started": "2021-10-01T08:49:51.242037Z"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "931b552bcf0e439eb18732abd836fa2b"
          ]
        },
        "id": "jH8zrc60EZAQ",
        "outputId": "34ed6453-69eb-4f2b-c4e9-5f467efadd1a"
      },
      "source": [
        "aug_swap_list = []\n",
        "aug_del_list = []\n",
        "aug_y_list = []\n",
        "\n",
        "aug_swap = naw.RandomWordAug(action=\"swap\")\n",
        "aug_del = naw.RandomWordAug()\n",
        "\n",
        "for i, data in tqdm(enumerate(X_train_data), total = len(X_train_data)):\n",
        "    \n",
        "    augmented_swap = aug_swap.augment(data)\n",
        "    augmented_del = aug_del.augment(data)\n",
        "    \n",
        "    aug_swap_list.append(augmented_swap)\n",
        "    aug_del_list.append(augmented_del)\n",
        "    \n",
        "    aug_y_list.append(y_train_data[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "931b552bcf0e439eb18732abd836fa2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/55134 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:58.123985Z",
          "iopub.status.busy": "2021-10-01T08:49:58.123760Z",
          "iopub.status.idle": "2021-10-01T08:49:58.127977Z",
          "shell.execute_reply": "2021-10-01T08:49:58.127333Z",
          "shell.execute_reply.started": "2021-10-01T08:49:58.123961Z"
        },
        "tags": [],
        "id": "NeLdViH-EZAQ",
        "outputId": "569e1b97-322a-4075-ea60-c332db2d2089"
      },
      "source": [
        "pprint(X_train_data[10000:10003])\n",
        "pprint(aug_swap_list[10000:10003])\n",
        "pprint(aug_del_list[10000:10003])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['이제 아들 차례네', '그 사람 얘기만 나오면 주눅 들구', '외국에서는 운전 중에 뒷좌석을 돌아보기만 해도 벌금은 매긴다더라']\n",
            "['아들 이제 차례네', '그 사람 얘기만 나오면 들구 주눅', '외국에서는 중에 운전 뒷좌석을 돌아보기만 벌금은 해도 매긴다더라']\n",
            "['이제 아들', '그 사람 얘기만 나오면 주눅', '운전 중에 뒷좌석을 돌아보기만 해도 벌금은 매긴다더라']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAXm0B5GEZAR"
      },
      "source": [
        "> 문제점: data가 pipeline을 통과하면서 augmented되어야 하는데, 처음부터 dataset이 $n$배로 뻥튀기됨. 따라서 학습 시간이 더 오래 걸릴 뿐만 아니라, 모델이 잘 학습되었는지 확인하기 위한 validation data까지 augmented됨에 따라, train acc와 val acc가 높아지는 반면 test acc는 오히려 떨어지는 결과가 야기됨. <br> <br>\n",
        "자연어 데이터를 pipeline 안에서 augmentation하는 방법?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:58.128988Z",
          "iopub.status.busy": "2021-10-01T08:49:58.128793Z",
          "iopub.status.idle": "2021-10-01T08:49:58.131774Z",
          "shell.execute_reply": "2021-10-01T08:49:58.131203Z",
          "shell.execute_reply.started": "2021-10-01T08:49:58.128966Z"
        },
        "id": "pvzdBZyjEZAS"
      },
      "source": [
        "# X_train_data.extend(aug_swap_list)\n",
        "# X_train_data.extend(aug_del_list)\n",
        "\n",
        "# y_train_data.extend(aug_y_list)\n",
        "# y_train_data.extend(aug_y_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:58.132716Z",
          "iopub.status.busy": "2021-10-01T08:49:58.132534Z",
          "iopub.status.idle": "2021-10-01T08:49:58.135366Z",
          "shell.execute_reply": "2021-10-01T08:49:58.134774Z",
          "shell.execute_reply.started": "2021-10-01T08:49:58.132695Z"
        },
        "tags": [],
        "id": "twAhZEqsEZAS"
      },
      "source": [
        "# print(len(X_train_data))\n",
        "# print(len(y_train_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTJ84Juqnqb4"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T14:20:52.641316Z",
          "iopub.status.busy": "2021-09-27T14:20:52.641019Z",
          "iopub.status.idle": "2021-09-27T14:20:52.644789Z",
          "shell.execute_reply": "2021-09-27T14:20:52.643995Z",
          "shell.execute_reply.started": "2021-09-27T14:20:52.641285Z"
        },
        "id": "F3fLr2xMEZAU"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:58.136376Z",
          "iopub.status.busy": "2021-10-01T08:49:58.136186Z",
          "iopub.status.idle": "2021-10-01T08:49:58.139860Z",
          "shell.execute_reply": "2021-10-01T08:49:58.139215Z",
          "shell.execute_reply.started": "2021-10-01T08:49:58.136355Z"
        },
        "tags": [],
        "id": "W-yqp7CYEZAU"
      },
      "source": [
        "# 위키독스의 불용어 목록\n",
        "\n",
        "stopwords_foo = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:58.140811Z",
          "iopub.status.busy": "2021-10-01T08:49:58.140630Z",
          "iopub.status.idle": "2021-10-01T08:49:58.151831Z",
          "shell.execute_reply": "2021-10-01T08:49:58.151225Z",
          "shell.execute_reply.started": "2021-10-01T08:49:58.140790Z"
        },
        "tags": [],
        "id": "O0AipPTjEZAV",
        "outputId": "fa16f38b-13ce-492b-da0f-d06b77c570a1"
      },
      "source": [
        "# https://bab2min.tistory.com/544\n",
        "\n",
        "df = pd.read_csv(\"stopword_data.txt\", sep='\\t', names=[\"word\", \"pos\", \"ratio\"])\n",
        "stopwords = df[\"word\"].tolist()\n",
        "stopwords.extend(stopwords_foo)\n",
        "print(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['이', '있', '하', '것', '들', '그', '되', '수', '이', '보', '않', '없', '나', '사람', '주', '아니', '등', '같', '우리', '때', '년', '가', '한', '지', '대하', '오', '말', '일', '그렇', '위하', '때문', '그것', '두', '말하', '알', '그러나', '받', '못하', '일', '그런', '또', '문제', '더', '사회', '많', '그리고', '좋', '크', '따르', '중', '나오', '가지', '씨', '시키', '만들', '지금', '생각하', '그러', '속', '하나', '집', '살', '모르', '적', '월', '데', '자신', '안', '어떤', '내', '내', '경우', '명', '생각', '시간', '그녀', '다시', '이런', '앞', '보이', '번', '나', '다른', '어떻', '여자', '개', '전', '들', '사실', '이렇', '점', '싶', '말', '정도', '좀', '원', '잘', '통하', '소리', '놓', '의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:49:58.152907Z",
          "iopub.status.busy": "2021-10-01T08:49:58.152720Z",
          "iopub.status.idle": "2021-10-01T08:51:41.005319Z",
          "shell.execute_reply": "2021-10-01T08:51:41.004493Z",
          "shell.execute_reply.started": "2021-10-01T08:49:58.152885Z"
        },
        "id": "sv7WUcJG3M6n",
        "tags": []
      },
      "source": [
        "pos_tagger = Okt()\n",
        "\n",
        "def tokenizing(doc):\n",
        "    x = [t[0] for t in pos_tagger.pos(doc) if not t[0] in stopwords]\n",
        "    \n",
        "    return ' '.join(x)\n",
        "\n",
        "X_train_token = [tokenizing(row) for row in X_train_data]\n",
        "X_test_token  = [tokenizing(row) for row in X_test_data]\n",
        "\n",
        "### nltk tokenizer로\n",
        "X_train_token_splitted = [nltk.word_tokenize(row) for row in X_train_token]\n",
        "X_test_token_splitted  = [nltk.word_tokenize(row) for row in X_test_token]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:41.006631Z",
          "iopub.status.busy": "2021-10-01T08:51:41.006401Z",
          "iopub.status.idle": "2021-10-01T08:51:41.010921Z",
          "shell.execute_reply": "2021-10-01T08:51:41.010259Z",
          "shell.execute_reply.started": "2021-10-01T08:51:41.006605Z"
        },
        "id": "PHLGqwmb3Mwu",
        "tags": [],
        "outputId": "8a65a130-ad19-4f47-bb9b-20ace4305d54"
      },
      "source": [
        "print(X_train_token[20000:20010])\n",
        "print(X_train_token_splitted[20000:20010])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['오늘 저녁 무슨 약속 있지', '현관문 닫혔는지 확인 해줘', '콜라 마요네즈 섞으면', '보일러 껐니', '청담동 가려면 뭐 타고 가야 하냐', '서울 근교 놀이 공원 어디 냐', '이번 달 있는 공휴일 얼마나 되니', '이번 토요일 오전 일곱시 도로 안개 끼니', '가스 불 끄고 나왔는지 확인 부탁 할게', '뜨개질 관련 메일 왔니']\n",
            "[['오늘', '저녁', '무슨', '약속', '있지'], ['현관문', '닫혔는지', '확인', '해줘'], ['콜라', '마요네즈', '섞으면'], ['보일러', '껐니'], ['청담동', '가려면', '뭐', '타고', '가야', '하냐'], ['서울', '근교', '놀이', '공원', '어디', '냐'], ['이번', '달', '있는', '공휴일', '얼마나', '되니'], ['이번', '토요일', '오전', '일곱시', '도로', '안개', '끼니'], ['가스', '불', '끄고', '나왔는지', '확인', '부탁', '할게'], ['뜨개질', '관련', '메일', '왔니']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTesb6GlEZAX"
      },
      "source": [
        "## 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:41.012072Z",
          "iopub.status.busy": "2021-10-01T08:51:41.011856Z",
          "iopub.status.idle": "2021-10-01T08:51:41.373627Z",
          "shell.execute_reply": "2021-10-01T08:51:41.372890Z",
          "shell.execute_reply.started": "2021-10-01T08:51:41.012049Z"
        },
        "tags": [],
        "id": "Nab6hzIvEZAY"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(X_train_token_splitted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:41.374873Z",
          "iopub.status.busy": "2021-10-01T08:51:41.374653Z",
          "iopub.status.idle": "2021-10-01T08:51:41.378803Z",
          "shell.execute_reply": "2021-10-01T08:51:41.378056Z",
          "shell.execute_reply.started": "2021-10-01T08:51:41.374848Z"
        },
        "tags": [],
        "id": "4WgPaCWzEZAY",
        "outputId": "5d05ca5a-3055-484f-851d-e97c8b5ab694"
      },
      "source": [
        "print(len(tokenizer.word_index))\n",
        "#print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:41.379824Z",
          "iopub.status.busy": "2021-10-01T08:51:41.379632Z",
          "iopub.status.idle": "2021-10-01T08:51:41.400187Z",
          "shell.execute_reply": "2021-10-01T08:51:41.399536Z",
          "shell.execute_reply.started": "2021-10-01T08:51:41.379801Z"
        },
        "tags": [],
        "id": "DsX92zypEZAY",
        "outputId": "e4d7c82d-5aa3-4c83-98b2-ce3e536876b3"
      },
      "source": [
        "threshold = 2\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 31358\n",
            "등장 빈도가 1번 이하인 희귀 단어의 수: 16078\n",
            "단어 집합에서 희귀 단어의 비율: 51.272402576694944\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.278328583997584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:41.401107Z",
          "iopub.status.busy": "2021-10-01T08:51:41.400917Z",
          "iopub.status.idle": "2021-10-01T08:51:41.405060Z",
          "shell.execute_reply": "2021-10-01T08:51:41.404314Z",
          "shell.execute_reply.started": "2021-10-01T08:51:41.401086Z"
        },
        "tags": [],
        "id": "pQoIddr6EZAZ",
        "outputId": "e17d1f0e-8476-46c4-8eef-007c2ab0ab79"
      },
      "source": [
        "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
        "# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print('단어 집합의 크기 :',vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 15282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:41.406039Z",
          "iopub.status.busy": "2021-10-01T08:51:41.405847Z",
          "iopub.status.idle": "2021-10-01T08:51:42.203105Z",
          "shell.execute_reply": "2021-10-01T08:51:42.202376Z",
          "shell.execute_reply.started": "2021-10-01T08:51:41.406017Z"
        },
        "tags": [],
        "id": "hphPEzV5EZAZ"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
        "tokenizer.fit_on_texts(X_train_token_splitted)\n",
        "X_train = tokenizer.texts_to_sequences(X_train_token_splitted)\n",
        "X_test = tokenizer.texts_to_sequences(X_test_token_splitted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:42.205166Z",
          "iopub.status.busy": "2021-10-01T08:51:42.204967Z",
          "iopub.status.idle": "2021-10-01T08:51:42.210512Z",
          "shell.execute_reply": "2021-10-01T08:51:42.209399Z",
          "shell.execute_reply.started": "2021-10-01T08:51:42.205141Z"
        },
        "tags": [],
        "id": "INnNNYILEZAa",
        "outputId": "4777421b-384a-4c35-9ba3-f6154615de5e"
      },
      "source": [
        "print(X_train[:3])\n",
        "print(X_test[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4600], [10534], [361]]\n",
            "[[1], [448], []]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T14:44:00.400901Z",
          "iopub.status.busy": "2021-09-27T14:44:00.400597Z",
          "iopub.status.idle": "2021-09-27T14:44:00.405382Z",
          "shell.execute_reply": "2021-09-27T14:44:00.404680Z",
          "shell.execute_reply.started": "2021-09-27T14:44:00.400871Z"
        },
        "tags": [],
        "id": "coxG4MYcEZAa"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:42.211537Z",
          "iopub.status.busy": "2021-10-01T08:51:42.211339Z",
          "iopub.status.idle": "2021-10-01T08:51:42.720065Z",
          "shell.execute_reply": "2021-10-01T08:51:42.719365Z",
          "shell.execute_reply.started": "2021-10-01T08:51:42.211514Z"
        },
        "tags": [],
        "id": "HlfODYoIEZAa",
        "outputId": "b14dfd5c-d9c6-43e9-f1d5-736aa05f2d35"
      },
      "source": [
        "print('문장의 최대 길이 :',max(len(l) for l in X_train))\n",
        "print('문장의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장의 최대 길이 : 36\n",
            "문장의 평균 길이 : 5.5247941379185255\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:42.722887Z",
          "iopub.status.busy": "2021-10-01T08:51:42.722666Z",
          "iopub.status.idle": "2021-10-01T08:51:42.727143Z",
          "shell.execute_reply": "2021-10-01T08:51:42.726451Z",
          "shell.execute_reply.started": "2021-10-01T08:51:42.722861Z"
        },
        "tags": [],
        "id": "FHrpkJ8tEZAb"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s) <= max_len):\n",
        "        cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:42.728515Z",
          "iopub.status.busy": "2021-10-01T08:51:42.728312Z",
          "iopub.status.idle": "2021-10-01T08:51:42.738224Z",
          "shell.execute_reply": "2021-10-01T08:51:42.737565Z",
          "shell.execute_reply.started": "2021-10-01T08:51:42.728492Z"
        },
        "tags": [],
        "id": "ua6E8hjpEZAb",
        "outputId": "246e8213-a1c7-49bd-9557-ae89bf56f11a"
      },
      "source": [
        "max_len = 15   # 17\n",
        "below_threshold_len(max_len, X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 샘플 중 길이가 15 이하인 샘플의 비율: 99.55925563173359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:42.739448Z",
          "iopub.status.busy": "2021-10-01T08:51:42.739118Z",
          "iopub.status.idle": "2021-10-01T08:51:42.996792Z",
          "shell.execute_reply": "2021-10-01T08:51:42.996125Z",
          "shell.execute_reply.started": "2021-10-01T08:51:42.739424Z"
        },
        "tags": [],
        "id": "YkyAYNI7EZAc"
      },
      "source": [
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)\n",
        "\n",
        "y_train = to_categorical(y_train_data)\n",
        "y_test = to_categorical(y_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:42.997986Z",
          "iopub.status.busy": "2021-10-01T08:51:42.997778Z",
          "iopub.status.idle": "2021-10-01T08:51:43.003765Z",
          "shell.execute_reply": "2021-10-01T08:51:43.003083Z",
          "shell.execute_reply.started": "2021-10-01T08:51:42.997962Z"
        },
        "id": "bhqwuvE35nuD",
        "tags": [],
        "outputId": "a856282f-0995-40f7-c957-f49c45148104"
      },
      "source": [
        "print(X_train[:3])\n",
        "print(X_test[:3])\n",
        "print(y_train[:3])\n",
        "print(y_test[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0  4600]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0 10534]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0   361]]\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 448]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "[[1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]]\n",
            "[[1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:43.004953Z",
          "iopub.status.busy": "2021-10-01T08:51:43.004761Z",
          "iopub.status.idle": "2021-10-01T08:51:43.464571Z",
          "shell.execute_reply": "2021-10-01T08:51:43.463686Z",
          "shell.execute_reply.started": "2021-10-01T08:51:43.004931Z"
        },
        "tags": [],
        "id": "IkzHh-22EZAc",
        "outputId": "cb531fb3-e556-4db9-f4c9-a4fea04e8422"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, stratify=y_train)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(46863, 15)\n",
            "(46863, 7)\n",
            "(8271, 15)\n",
            "(8271, 7)\n",
            "(6121, 15)\n",
            "(6121, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsRgHjmsEZAd"
      },
      "source": [
        "# Pretrained Embedding Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:43.465793Z",
          "iopub.status.busy": "2021-10-01T08:51:43.465579Z",
          "iopub.status.idle": "2021-10-01T08:51:52.338280Z",
          "shell.execute_reply": "2021-10-01T08:51:52.337573Z",
          "shell.execute_reply.started": "2021-10-01T08:51:43.465767Z"
        },
        "tags": [],
        "id": "ILiPknDKEZAd"
      },
      "source": [
        "loaded_model = FT_gensim.load_fasttext_format('vectors/model_drama.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:52.339504Z",
          "iopub.status.busy": "2021-10-01T08:51:52.339299Z",
          "iopub.status.idle": "2021-10-01T08:51:52.345146Z",
          "shell.execute_reply": "2021-10-01T08:51:52.343438Z",
          "shell.execute_reply.started": "2021-10-01T08:51:52.339480Z"
        },
        "tags": [],
        "id": "fdy9hM_SEZAe",
        "outputId": "94152495-f7a3-4bd7-d3ab-17e2e4194269"
      },
      "source": [
        "print(loaded_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastText(vocab=160043, size=100, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:52.346121Z",
          "iopub.status.busy": "2021-10-01T08:51:52.345929Z",
          "iopub.status.idle": "2021-10-01T08:51:53.243331Z",
          "shell.execute_reply": "2021-10-01T08:51:53.242762Z",
          "shell.execute_reply.started": "2021-10-01T08:51:52.346098Z"
        },
        "tags": [],
        "id": "BH5vZhGPEZAe",
        "outputId": "1e758bc3-3300-4c38-e79e-b404e4270c2b"
      },
      "source": [
        "print('안녕' in loaded_model.wv.vocab)\n",
        "print(loaded_model.most_similar(\"안녕\"))\n",
        "print(loaded_model['안녕'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/envs/psd/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('왔으니깐', 0.7077229619026184), ('하였더니', 0.689039409160614), ('재석이', 0.665482759475708), ('해주시기', 0.6634321808815002), ('고생시켜서', 0.6615829467773438), ('이호진의', 0.6615034341812134), ('그곳으로', 0.6586490869522095), ('병석이', 0.6558609008789062), ('희재', 0.6556533575057983), ('무브', 0.6513947248458862)]\n",
            "[-0.20837323  0.21626383  0.0054911   0.07921323  0.203135    0.03575059\n",
            " -0.12396514  0.174983    0.2385913   0.20969039 -0.06152691 -0.05342709\n",
            "  0.00817227  0.0137452   0.25210565  0.14207946 -0.0069862   0.07155829\n",
            " -0.11726188 -0.01571709 -0.18182424 -0.04145883  0.06458063 -0.13819216\n",
            " -0.04949455  0.10642069  0.10609311 -0.05291022 -0.25471207 -0.06118836\n",
            "  0.07871876 -0.02403206  0.05075282 -0.13062136 -0.03300982  0.00239827\n",
            " -0.20694333 -0.09797629 -0.04896694  0.1861868  -0.03632177 -0.01879727\n",
            " -0.05107179  0.07315976 -0.06730977 -0.17247403 -0.04448244  0.03694947\n",
            " -0.1605727  -0.15880612  0.09569672  0.31981894 -0.03940499 -0.02544998\n",
            " -0.03745533  0.06832626 -0.00944789 -0.17063852 -0.06772653 -0.13011421\n",
            " -0.06931078  0.03487949 -0.21680628 -0.01007261 -0.04196937  0.00295484\n",
            "  0.24279918  0.24640991 -0.09263007  0.12259059 -0.01626277 -0.02440865\n",
            " -0.05974907  0.02232739 -0.03351026  0.33445835  0.23039845 -0.02479115\n",
            "  0.07557323 -0.1628316   0.26275724 -0.03214483 -0.0768776  -0.17786068\n",
            "  0.20124416  0.04288509  0.12540624  0.12775904 -0.10604636  0.07076482\n",
            " -0.06334376 -0.14396504  0.06334752  0.16843295 -0.09358874  0.05027393\n",
            " -0.18819189  0.11665804 -0.02374548 -0.01622548]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/envs/psd/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:53.244512Z",
          "iopub.status.busy": "2021-10-01T08:51:53.244298Z",
          "iopub.status.idle": "2021-10-01T08:51:53.247124Z",
          "shell.execute_reply": "2021-10-01T08:51:53.246617Z",
          "shell.execute_reply.started": "2021-10-01T08:51:53.244481Z"
        },
        "tags": [],
        "id": "ai6DpCEWEZAe"
      },
      "source": [
        "#tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
        "#tokenizer.fit_on_texts(X_train_token_splitted)\n",
        "\n",
        "#X_train = tokenizer.texts_to_sequences(X_train_token_splitted)\n",
        "#X_test = tokenizer.texts_to_sequences(X_test_token_splitted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:53.248163Z",
          "iopub.status.busy": "2021-10-01T08:51:53.247965Z",
          "iopub.status.idle": "2021-10-01T08:51:53.894662Z",
          "shell.execute_reply": "2021-10-01T08:51:53.894033Z",
          "shell.execute_reply.started": "2021-10-01T08:51:53.248141Z"
        },
        "tags": [],
        "id": "Eo3e3ZEvEZAf",
        "outputId": "bd825401-18b9-42de-b616-46ef929355e5"
      },
      "source": [
        "embedding_matrix = np.zeros((total_cnt + 2, 100))   # 왜 vocab_size로는 못 하지?\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in loaded_model:\n",
        "        #print(word)\n",
        "        embedding_vector = loaded_model[word]\n",
        "    else:\n",
        "        continue\n",
        "        \n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/envs/psd/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/home/ubuntu/anaconda3/envs/psd/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:53.895798Z",
          "iopub.status.busy": "2021-10-01T08:51:53.895594Z",
          "iopub.status.idle": "2021-10-01T08:51:53.899857Z",
          "shell.execute_reply": "2021-10-01T08:51:53.899380Z",
          "shell.execute_reply.started": "2021-10-01T08:51:53.895773Z"
        },
        "tags": [],
        "id": "5v--ndCWEZAf",
        "outputId": "f3961e88-3d94-42fe-8511-920e6e7bedcf"
      },
      "source": [
        "print(embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.0201662   0.0789165   0.00863309 ... -0.09077461 -0.07218648\n",
            "  -0.11439495]\n",
            " [ 0.19867121 -0.08441713 -0.08691589 ... -0.07481183  0.09989324\n",
            "  -0.41806331]\n",
            " ...\n",
            " [ 0.00954878  0.0017603   0.00534863 ...  0.01200104 -0.04521481\n",
            "   0.02055699]\n",
            " [ 0.01491402  0.01213227 -0.00414175 ... -0.06965395  0.01472734\n",
            "  -0.08061473]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:53.900752Z",
          "iopub.status.busy": "2021-10-01T08:51:53.900568Z",
          "iopub.status.idle": "2021-10-01T08:51:53.904614Z",
          "shell.execute_reply": "2021-10-01T08:51:53.904072Z",
          "shell.execute_reply.started": "2021-10-01T08:51:53.900730Z"
        },
        "tags": [],
        "id": "UmDiDBJ9EZAg",
        "outputId": "03023280-a66b-4663-e6ee-64ff5502792a"
      },
      "source": [
        "print('단어 안녕의 정수 인덱스 :', tokenizer.word_index['안녕'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 안녕의 정수 인덱스 : 4605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:53.905667Z",
          "iopub.status.busy": "2021-10-01T08:51:53.905382Z",
          "iopub.status.idle": "2021-10-01T08:51:53.909735Z",
          "shell.execute_reply": "2021-10-01T08:51:53.909113Z",
          "shell.execute_reply.started": "2021-10-01T08:51:53.905644Z"
        },
        "tags": [],
        "id": "Tt11sxJcEZAg",
        "outputId": "4d11fef0-8591-4b85-f60a-e41d6108e25f"
      },
      "source": [
        "print(embedding_matrix[4605])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.20837323  0.21626383  0.0054911   0.07921323  0.203135    0.03575059\n",
            " -0.12396514  0.17498299  0.2385913   0.20969039 -0.06152691 -0.05342709\n",
            "  0.00817227  0.0137452   0.25210565  0.14207946 -0.0069862   0.07155829\n",
            " -0.11726188 -0.01571709 -0.18182424 -0.04145883  0.06458063 -0.13819216\n",
            " -0.04949455  0.10642069  0.10609311 -0.05291022 -0.25471207 -0.06118836\n",
            "  0.07871876 -0.02403206  0.05075282 -0.13062136 -0.03300982  0.00239827\n",
            " -0.20694333 -0.09797629 -0.04896694  0.18618681 -0.03632177 -0.01879727\n",
            " -0.05107179  0.07315976 -0.06730977 -0.17247403 -0.04448244  0.03694947\n",
            " -0.16057269 -0.15880612  0.09569672  0.31981894 -0.03940499 -0.02544998\n",
            " -0.03745533  0.06832626 -0.00944789 -0.17063852 -0.06772653 -0.13011421\n",
            " -0.06931078  0.03487949 -0.21680628 -0.01007261 -0.04196937  0.00295484\n",
            "  0.24279918  0.24640991 -0.09263007  0.12259059 -0.01626277 -0.02440865\n",
            " -0.05974907  0.02232739 -0.03351026  0.33445835  0.23039845 -0.02479115\n",
            "  0.07557323 -0.1628316   0.26275724 -0.03214483 -0.0768776  -0.17786068\n",
            "  0.20124416  0.04288509  0.12540624  0.12775904 -0.10604636  0.07076482\n",
            " -0.06334376 -0.14396504  0.06334752  0.16843295 -0.09358874  0.05027393\n",
            " -0.18819189  0.11665804 -0.02374548 -0.01622548]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:53.910631Z",
          "iopub.status.busy": "2021-10-01T08:51:53.910449Z",
          "iopub.status.idle": "2021-10-01T08:51:53.914832Z",
          "shell.execute_reply": "2021-10-01T08:51:53.914342Z",
          "shell.execute_reply.started": "2021-10-01T08:51:53.910610Z"
        },
        "tags": [],
        "id": "G-_iPY0EEZAg",
        "outputId": "50b757c3-9cbb-4360-98fc-a353344ce584"
      },
      "source": [
        "print(loaded_model['안녕'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.20837323  0.21626383  0.0054911   0.07921323  0.203135    0.03575059\n",
            " -0.12396514  0.174983    0.2385913   0.20969039 -0.06152691 -0.05342709\n",
            "  0.00817227  0.0137452   0.25210565  0.14207946 -0.0069862   0.07155829\n",
            " -0.11726188 -0.01571709 -0.18182424 -0.04145883  0.06458063 -0.13819216\n",
            " -0.04949455  0.10642069  0.10609311 -0.05291022 -0.25471207 -0.06118836\n",
            "  0.07871876 -0.02403206  0.05075282 -0.13062136 -0.03300982  0.00239827\n",
            " -0.20694333 -0.09797629 -0.04896694  0.1861868  -0.03632177 -0.01879727\n",
            " -0.05107179  0.07315976 -0.06730977 -0.17247403 -0.04448244  0.03694947\n",
            " -0.1605727  -0.15880612  0.09569672  0.31981894 -0.03940499 -0.02544998\n",
            " -0.03745533  0.06832626 -0.00944789 -0.17063852 -0.06772653 -0.13011421\n",
            " -0.06931078  0.03487949 -0.21680628 -0.01007261 -0.04196937  0.00295484\n",
            "  0.24279918  0.24640991 -0.09263007  0.12259059 -0.01626277 -0.02440865\n",
            " -0.05974907  0.02232739 -0.03351026  0.33445835  0.23039845 -0.02479115\n",
            "  0.07557323 -0.1628316   0.26275724 -0.03214483 -0.0768776  -0.17786068\n",
            "  0.20124416  0.04288509  0.12540624  0.12775904 -0.10604636  0.07076482\n",
            " -0.06334376 -0.14396504  0.06334752  0.16843295 -0.09358874  0.05027393\n",
            " -0.18819189  0.11665804 -0.02374548 -0.01622548]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/envs/psd/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpbtjVbEEZAh"
      },
      "source": [
        "# Modeling 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:51:53.915859Z",
          "iopub.status.busy": "2021-10-01T08:51:53.915674Z",
          "iopub.status.idle": "2021-10-01T08:52:00.090497Z",
          "shell.execute_reply": "2021-10-01T08:52:00.089711Z",
          "shell.execute_reply.started": "2021-10-01T08:51:53.915837Z"
        },
        "id": "NNBOz9Yx8QGI",
        "tags": []
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "#model.add(Embedding(vocab_size, 100))\n",
        "model.add(Embedding(total_cnt + 2 , 100, weights=[embedding_matrix], embeddings_initializer=\"glorot_normal\", trainable=True))\n",
        "model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(100)))\n",
        "model.add(Dense(7, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:52:00.091642Z",
          "iopub.status.busy": "2021-10-01T08:52:00.091434Z",
          "iopub.status.idle": "2021-10-01T08:52:00.095595Z",
          "shell.execute_reply": "2021-10-01T08:52:00.094841Z",
          "shell.execute_reply.started": "2021-10-01T08:52:00.091617Z"
        },
        "tags": [],
        "id": "d2T-sVxgEZAi"
      },
      "source": [
        "lr_Cosine_Decay = CosineDecayRestarts(\n",
        "    initial_learning_rate=(1e-4), first_decay_steps=92,   # 87\n",
        "    t_mul=2, m_mul=0.80, alpha=0.0, name=None   #0.75\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-10-01T08:52:00.096780Z",
          "iopub.status.busy": "2021-10-01T08:52:00.096584Z",
          "iopub.status.idle": "2021-10-01T08:52:00.138492Z",
          "shell.execute_reply": "2021-10-01T08:52:00.137715Z",
          "shell.execute_reply.started": "2021-10-01T08:52:00.096757Z"
        },
        "id": "yrpKXF5b9m-m",
        "tags": [],
        "outputId": "4b038df8-7719-4090-aa7a-a801681eb005"
      },
      "source": [
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "\n",
        "f1 = F1Score(num_classes=7, name=\"F1\")\n",
        "weighted_f1 = F1Score(num_classes=7, average=\"weighted\", name=\"Weighted_F1\")\n",
        "\n",
        "model.compile(optimizer=AdamW(lr_Cosine_Decay), loss=\"categorical_crossentropy\", metrics=[\"acc\", f1, weighted_f1])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         3136000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 200)         160800    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 200)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 200)         240800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 200)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 200)               240800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7)                 1407      \n",
            "=================================================================\n",
            "Total params: 3,779,807\n",
            "Trainable params: 3,779,807\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyTwal_VEZAj"
      },
      "source": [
        "> 문제점: Epoch를 두세 번만 돌면 loss 최저점을 찍고 이후로 loss가 폭발적으로 증가한다. -> 무엇이 문제일지?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:52:00.139538Z",
          "iopub.status.busy": "2021-10-01T08:52:00.139285Z",
          "iopub.status.idle": "2021-10-01T08:55:28.987185Z",
          "shell.execute_reply": "2021-10-01T08:55:28.986567Z",
          "shell.execute_reply.started": "2021-10-01T08:52:00.139499Z"
        },
        "tags": [],
        "id": "FvcSvM5fEZAj",
        "outputId": "d8ab55ed-179d-4979-af9d-a68a4b874068"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=63, validation_data=(X_val, y_val), callbacks=[mc], batch_size=512, class_weight=class_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 1.2093 - acc: 0.6120 - F1: 0.3780 - Weighted_F1: 0.5784\n",
            "Epoch 00001: val_loss improved from inf to 0.67024, saving model to best_model.h5\n",
            "92/92 [==============================] - 6s 70ms/step - loss: 1.2063 - acc: 0.6130 - F1: 0.3790 - Weighted_F1: 0.5796 - val_loss: 0.6702 - val_acc: 0.7789 - val_F1: 0.5464 - val_Weighted_F1: 0.7594\n",
            "Epoch 2/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.6348 - acc: 0.8272 - F1: 0.6517 - Weighted_F1: 0.8196\n",
            "Epoch 00002: val_loss improved from 0.67024 to 0.53857, saving model to best_model.h5\n",
            "92/92 [==============================] - 4s 42ms/step - loss: 0.6348 - acc: 0.8272 - F1: 0.6517 - Weighted_F1: 0.8196 - val_loss: 0.5386 - val_acc: 0.8280 - val_F1: 0.6763 - val_Weighted_F1: 0.8230\n",
            "Epoch 3/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.4368 - acc: 0.8767 - F1: 0.7656 - Weighted_F1: 0.8765\n",
            "Epoch 00003: val_loss improved from 0.53857 to 0.49500, saving model to best_model.h5\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 0.4368 - acc: 0.8767 - F1: 0.7656 - Weighted_F1: 0.8765 - val_loss: 0.4950 - val_acc: 0.8456 - val_F1: 0.7302 - val_Weighted_F1: 0.8425\n",
            "Epoch 4/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.3237 - acc: 0.9078 - F1: 0.8360 - Weighted_F1: 0.9078\n",
            "Epoch 00004: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.3237 - acc: 0.9078 - F1: 0.8360 - Weighted_F1: 0.9078 - val_loss: 0.5076 - val_acc: 0.8443 - val_F1: 0.7401 - val_Weighted_F1: 0.8434\n",
            "Epoch 5/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.2615 - acc: 0.9257 - F1: 0.8720 - Weighted_F1: 0.9260\n",
            "Epoch 00005: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.2612 - acc: 0.9258 - F1: 0.8720 - Weighted_F1: 0.9260 - val_loss: 0.5601 - val_acc: 0.8358 - val_F1: 0.7301 - val_Weighted_F1: 0.8382\n",
            "Epoch 6/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.2183 - acc: 0.9374 - F1: 0.8941 - Weighted_F1: 0.9376\n",
            "Epoch 00006: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.2186 - acc: 0.9373 - F1: 0.8938 - Weighted_F1: 0.9375 - val_loss: 0.5816 - val_acc: 0.8361 - val_F1: 0.7283 - val_Weighted_F1: 0.8355\n",
            "Epoch 7/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9453 - F1: 0.9094 - Weighted_F1: 0.9455\n",
            "Epoch 00007: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.1913 - acc: 0.9453 - F1: 0.9094 - Weighted_F1: 0.9455 - val_loss: 0.6267 - val_acc: 0.8338 - val_F1: 0.7266 - val_Weighted_F1: 0.8350\n",
            "Epoch 8/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9510 - F1: 0.9174 - Weighted_F1: 0.9512\n",
            "Epoch 00008: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 0.1713 - acc: 0.9511 - F1: 0.9177 - Weighted_F1: 0.9513 - val_loss: 0.6570 - val_acc: 0.8339 - val_F1: 0.7325 - val_Weighted_F1: 0.8338\n",
            "Epoch 9/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9565 - F1: 0.9282 - Weighted_F1: 0.9567\n",
            "Epoch 00009: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.1537 - acc: 0.9565 - F1: 0.9279 - Weighted_F1: 0.9567 - val_loss: 0.6583 - val_acc: 0.8263 - val_F1: 0.7193 - val_Weighted_F1: 0.8262\n",
            "Epoch 10/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9593 - F1: 0.9334 - Weighted_F1: 0.9595\n",
            "Epoch 00010: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.1419 - acc: 0.9593 - F1: 0.9334 - Weighted_F1: 0.9595 - val_loss: 0.6832 - val_acc: 0.8286 - val_F1: 0.7234 - val_Weighted_F1: 0.8309\n",
            "Epoch 11/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9625 - F1: 0.9395 - Weighted_F1: 0.9626\n",
            "Epoch 00011: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.1319 - acc: 0.9623 - F1: 0.9394 - Weighted_F1: 0.9624 - val_loss: 0.7578 - val_acc: 0.8231 - val_F1: 0.7223 - val_Weighted_F1: 0.8253\n",
            "Epoch 12/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9658 - F1: 0.9426 - Weighted_F1: 0.9659\n",
            "Epoch 00012: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.1225 - acc: 0.9658 - F1: 0.9426 - Weighted_F1: 0.9659 - val_loss: 0.7642 - val_acc: 0.8271 - val_F1: 0.7270 - val_Weighted_F1: 0.8297\n",
            "Epoch 13/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.1141 - acc: 0.9681 - F1: 0.9464 - Weighted_F1: 0.9683\n",
            "Epoch 00013: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.1141 - acc: 0.9681 - F1: 0.9464 - Weighted_F1: 0.9683 - val_loss: 0.7799 - val_acc: 0.8281 - val_F1: 0.7294 - val_Weighted_F1: 0.8296\n",
            "Epoch 14/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9700 - F1: 0.9501 - Weighted_F1: 0.9701\n",
            "Epoch 00014: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.1054 - acc: 0.9700 - F1: 0.9501 - Weighted_F1: 0.9701 - val_loss: 0.8128 - val_acc: 0.8251 - val_F1: 0.7278 - val_Weighted_F1: 0.8257\n",
            "Epoch 15/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9705 - F1: 0.9498 - Weighted_F1: 0.9707\n",
            "Epoch 00015: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.1020 - acc: 0.9705 - F1: 0.9496 - Weighted_F1: 0.9706 - val_loss: 0.8629 - val_acc: 0.8248 - val_F1: 0.7268 - val_Weighted_F1: 0.8257\n",
            "Epoch 16/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0954 - acc: 0.9723 - F1: 0.9545 - Weighted_F1: 0.9724\n",
            "Epoch 00016: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0954 - acc: 0.9723 - F1: 0.9545 - Weighted_F1: 0.9724 - val_loss: 0.8860 - val_acc: 0.8191 - val_F1: 0.7159 - val_Weighted_F1: 0.8214\n",
            "Epoch 17/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9726 - F1: 0.9524 - Weighted_F1: 0.9726\n",
            "Epoch 00017: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0948 - acc: 0.9726 - F1: 0.9524 - Weighted_F1: 0.9727 - val_loss: 0.8511 - val_acc: 0.8228 - val_F1: 0.7220 - val_Weighted_F1: 0.8239\n",
            "Epoch 18/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9744 - F1: 0.9558 - Weighted_F1: 0.9744\n",
            "Epoch 00018: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0890 - acc: 0.9744 - F1: 0.9557 - Weighted_F1: 0.9745 - val_loss: 0.8716 - val_acc: 0.8224 - val_F1: 0.7257 - val_Weighted_F1: 0.8254\n",
            "Epoch 19/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9750 - F1: 0.9550 - Weighted_F1: 0.9751\n",
            "Epoch 00019: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0861 - acc: 0.9750 - F1: 0.9551 - Weighted_F1: 0.9751 - val_loss: 0.8954 - val_acc: 0.8235 - val_F1: 0.7284 - val_Weighted_F1: 0.8238\n",
            "Epoch 20/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9771 - F1: 0.9601 - Weighted_F1: 0.9771\n",
            "Epoch 00020: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0796 - acc: 0.9770 - F1: 0.9602 - Weighted_F1: 0.9771 - val_loss: 0.9060 - val_acc: 0.8229 - val_F1: 0.7242 - val_Weighted_F1: 0.8241\n",
            "Epoch 21/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9791 - F1: 0.9630 - Weighted_F1: 0.9792\n",
            "Epoch 00021: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0730 - acc: 0.9791 - F1: 0.9630 - Weighted_F1: 0.9792 - val_loss: 0.9697 - val_acc: 0.8270 - val_F1: 0.7320 - val_Weighted_F1: 0.8273\n",
            "Epoch 22/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9787 - F1: 0.9627 - Weighted_F1: 0.9787\n",
            "Epoch 00022: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0739 - acc: 0.9787 - F1: 0.9627 - Weighted_F1: 0.9787 - val_loss: 0.9919 - val_acc: 0.8249 - val_F1: 0.7202 - val_Weighted_F1: 0.8243\n",
            "Epoch 23/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9790 - F1: 0.9610 - Weighted_F1: 0.9790\n",
            "Epoch 00023: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 0.0721 - acc: 0.9790 - F1: 0.9611 - Weighted_F1: 0.9790 - val_loss: 0.9643 - val_acc: 0.8223 - val_F1: 0.7252 - val_Weighted_F1: 0.8226\n",
            "Epoch 24/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9802 - F1: 0.9637 - Weighted_F1: 0.9803\n",
            "Epoch 00024: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0679 - acc: 0.9802 - F1: 0.9635 - Weighted_F1: 0.9802 - val_loss: 1.0083 - val_acc: 0.8199 - val_F1: 0.7196 - val_Weighted_F1: 0.8212\n",
            "Epoch 25/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9802 - F1: 0.9630 - Weighted_F1: 0.9803\n",
            "Epoch 00025: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0665 - acc: 0.9802 - F1: 0.9630 - Weighted_F1: 0.9803 - val_loss: 1.0064 - val_acc: 0.8208 - val_F1: 0.7261 - val_Weighted_F1: 0.8217\n",
            "Epoch 26/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9830 - F1: 0.9680 - Weighted_F1: 0.9830\n",
            "Epoch 00026: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0613 - acc: 0.9830 - F1: 0.9679 - Weighted_F1: 0.9830 - val_loss: 1.0600 - val_acc: 0.8261 - val_F1: 0.7254 - val_Weighted_F1: 0.8252\n",
            "Epoch 27/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9822 - F1: 0.9668 - Weighted_F1: 0.9822\n",
            "Epoch 00027: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0621 - acc: 0.9822 - F1: 0.9667 - Weighted_F1: 0.9822 - val_loss: 1.0379 - val_acc: 0.8238 - val_F1: 0.7241 - val_Weighted_F1: 0.8244\n",
            "Epoch 28/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0639 - acc: 0.9815 - F1: 0.9659 - Weighted_F1: 0.9816\n",
            "Epoch 00028: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0639 - acc: 0.9815 - F1: 0.9659 - Weighted_F1: 0.9816 - val_loss: 1.0289 - val_acc: 0.8219 - val_F1: 0.7205 - val_Weighted_F1: 0.8232\n",
            "Epoch 29/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9825 - F1: 0.9663 - Weighted_F1: 0.9826\n",
            "Epoch 00029: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0600 - acc: 0.9825 - F1: 0.9663 - Weighted_F1: 0.9826 - val_loss: 1.0709 - val_acc: 0.8252 - val_F1: 0.7220 - val_Weighted_F1: 0.8264\n",
            "Epoch 30/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0610 - acc: 0.9817 - F1: 0.9664 - Weighted_F1: 0.9817\n",
            "Epoch 00030: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0610 - acc: 0.9817 - F1: 0.9664 - Weighted_F1: 0.9817 - val_loss: 1.0639 - val_acc: 0.8136 - val_F1: 0.7149 - val_Weighted_F1: 0.8164\n",
            "Epoch 31/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9835 - F1: 0.9681 - Weighted_F1: 0.9835\n",
            "Epoch 00031: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0564 - acc: 0.9834 - F1: 0.9679 - Weighted_F1: 0.9835 - val_loss: 1.0692 - val_acc: 0.8254 - val_F1: 0.7261 - val_Weighted_F1: 0.8260\n",
            "Epoch 32/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9835 - F1: 0.9693 - Weighted_F1: 0.9836\n",
            "Epoch 00032: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0559 - acc: 0.9835 - F1: 0.9693 - Weighted_F1: 0.9836 - val_loss: 1.0738 - val_acc: 0.8184 - val_F1: 0.7209 - val_Weighted_F1: 0.8200\n",
            "Epoch 33/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9848 - F1: 0.9716 - Weighted_F1: 0.9849\n",
            "Epoch 00033: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0506 - acc: 0.9848 - F1: 0.9717 - Weighted_F1: 0.9849 - val_loss: 1.1169 - val_acc: 0.8224 - val_F1: 0.7256 - val_Weighted_F1: 0.8230\n",
            "Epoch 34/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0474 - acc: 0.9856 - F1: 0.9721 - Weighted_F1: 0.9856\n",
            "Epoch 00034: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0474 - acc: 0.9856 - F1: 0.9721 - Weighted_F1: 0.9856 - val_loss: 1.1160 - val_acc: 0.8225 - val_F1: 0.7217 - val_Weighted_F1: 0.8230\n",
            "Epoch 35/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0501 - acc: 0.9850 - F1: 0.9706 - Weighted_F1: 0.9850\n",
            "Epoch 00035: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0501 - acc: 0.9850 - F1: 0.9706 - Weighted_F1: 0.9850 - val_loss: 1.1248 - val_acc: 0.8257 - val_F1: 0.7171 - val_Weighted_F1: 0.8265\n",
            "Epoch 36/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9834 - F1: 0.9678 - Weighted_F1: 0.9835\n",
            "Epoch 00036: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 0.0566 - acc: 0.9834 - F1: 0.9677 - Weighted_F1: 0.9835 - val_loss: 1.1114 - val_acc: 0.8219 - val_F1: 0.7226 - val_Weighted_F1: 0.8229\n",
            "Epoch 37/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9848 - F1: 0.9710 - Weighted_F1: 0.9848\n",
            "Epoch 00037: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 0.0513 - acc: 0.9848 - F1: 0.9710 - Weighted_F1: 0.9849 - val_loss: 1.0953 - val_acc: 0.8225 - val_F1: 0.7262 - val_Weighted_F1: 0.8230\n",
            "Epoch 38/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9861 - F1: 0.9718 - Weighted_F1: 0.9861\n",
            "Epoch 00038: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0451 - acc: 0.9861 - F1: 0.9719 - Weighted_F1: 0.9861 - val_loss: 1.1743 - val_acc: 0.8179 - val_F1: 0.7136 - val_Weighted_F1: 0.8196\n",
            "Epoch 39/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0444 - acc: 0.9867 - F1: 0.9736 - Weighted_F1: 0.9868\n",
            "Epoch 00039: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0444 - acc: 0.9867 - F1: 0.9736 - Weighted_F1: 0.9868 - val_loss: 1.1609 - val_acc: 0.8236 - val_F1: 0.7229 - val_Weighted_F1: 0.8250\n",
            "Epoch 40/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9874 - F1: 0.9744 - Weighted_F1: 0.9874\n",
            "Epoch 00040: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 0.0421 - acc: 0.9874 - F1: 0.9745 - Weighted_F1: 0.9875 - val_loss: 1.1839 - val_acc: 0.8229 - val_F1: 0.7255 - val_Weighted_F1: 0.8239\n",
            "Epoch 41/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9863 - F1: 0.9720 - Weighted_F1: 0.9864\n",
            "Epoch 00041: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0452 - acc: 0.9863 - F1: 0.9720 - Weighted_F1: 0.9864 - val_loss: 1.2177 - val_acc: 0.8218 - val_F1: 0.7239 - val_Weighted_F1: 0.8225\n",
            "Epoch 42/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9854 - F1: 0.9727 - Weighted_F1: 0.9854\n",
            "Epoch 00042: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0471 - acc: 0.9854 - F1: 0.9728 - Weighted_F1: 0.9855 - val_loss: 1.1735 - val_acc: 0.8173 - val_F1: 0.7164 - val_Weighted_F1: 0.8197\n",
            "Epoch 43/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9852 - F1: 0.9694 - Weighted_F1: 0.9853\n",
            "Epoch 00043: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0460 - acc: 0.9853 - F1: 0.9695 - Weighted_F1: 0.9853 - val_loss: 1.2116 - val_acc: 0.8209 - val_F1: 0.7172 - val_Weighted_F1: 0.8206\n",
            "Epoch 44/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9861 - F1: 0.9724 - Weighted_F1: 0.9861\n",
            "Epoch 00044: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0463 - acc: 0.9861 - F1: 0.9724 - Weighted_F1: 0.9862 - val_loss: 1.1989 - val_acc: 0.8203 - val_F1: 0.7211 - val_Weighted_F1: 0.8196\n",
            "Epoch 45/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0448 - acc: 0.9861 - F1: 0.9721 - Weighted_F1: 0.9862\n",
            "Epoch 00045: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 0.0448 - acc: 0.9861 - F1: 0.9721 - Weighted_F1: 0.9862 - val_loss: 1.1967 - val_acc: 0.8220 - val_F1: 0.7251 - val_Weighted_F1: 0.8231\n",
            "Epoch 46/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9870 - F1: 0.9741 - Weighted_F1: 0.9871\n",
            "Epoch 00046: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0417 - acc: 0.9871 - F1: 0.9742 - Weighted_F1: 0.9871 - val_loss: 1.2174 - val_acc: 0.8167 - val_F1: 0.7218 - val_Weighted_F1: 0.8189\n",
            "Epoch 47/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9876 - F1: 0.9745 - Weighted_F1: 0.9876\n",
            "Epoch 00047: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0412 - acc: 0.9876 - F1: 0.9745 - Weighted_F1: 0.9876 - val_loss: 1.2017 - val_acc: 0.8230 - val_F1: 0.7236 - val_Weighted_F1: 0.8228\n",
            "Epoch 48/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0382 - acc: 0.9881 - F1: 0.9762 - Weighted_F1: 0.9881\n",
            "Epoch 00048: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0382 - acc: 0.9881 - F1: 0.9762 - Weighted_F1: 0.9881 - val_loss: 1.2297 - val_acc: 0.8207 - val_F1: 0.7191 - val_Weighted_F1: 0.8205\n",
            "Epoch 49/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9877 - F1: 0.9736 - Weighted_F1: 0.9877\n",
            "Epoch 00049: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0399 - acc: 0.9876 - F1: 0.9735 - Weighted_F1: 0.9877 - val_loss: 1.2904 - val_acc: 0.8255 - val_F1: 0.7249 - val_Weighted_F1: 0.8261\n",
            "Epoch 50/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9860 - F1: 0.9723 - Weighted_F1: 0.9860\n",
            "Epoch 00050: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0437 - acc: 0.9860 - F1: 0.9722 - Weighted_F1: 0.9860 - val_loss: 1.1526 - val_acc: 0.8230 - val_F1: 0.7213 - val_Weighted_F1: 0.8229\n",
            "Epoch 51/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9875 - F1: 0.9752 - Weighted_F1: 0.9875\n",
            "Epoch 00051: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0400 - acc: 0.9874 - F1: 0.9751 - Weighted_F1: 0.9874 - val_loss: 1.2179 - val_acc: 0.8196 - val_F1: 0.7138 - val_Weighted_F1: 0.8191\n",
            "Epoch 52/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9878 - F1: 0.9747 - Weighted_F1: 0.9878\n",
            "Epoch 00052: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0374 - acc: 0.9878 - F1: 0.9747 - Weighted_F1: 0.9878 - val_loss: 1.2645 - val_acc: 0.8219 - val_F1: 0.7233 - val_Weighted_F1: 0.8220\n",
            "Epoch 53/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0381 - acc: 0.9882 - F1: 0.9762 - Weighted_F1: 0.9883\n",
            "Epoch 00053: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0381 - acc: 0.9882 - F1: 0.9762 - Weighted_F1: 0.9883 - val_loss: 1.2895 - val_acc: 0.8243 - val_F1: 0.7296 - val_Weighted_F1: 0.8231\n",
            "Epoch 54/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9878 - F1: 0.9742 - Weighted_F1: 0.9878\n",
            "Epoch 00054: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0374 - acc: 0.9878 - F1: 0.9742 - Weighted_F1: 0.9878 - val_loss: 1.3258 - val_acc: 0.8150 - val_F1: 0.7160 - val_Weighted_F1: 0.8160\n",
            "Epoch 55/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9874 - F1: 0.9744 - Weighted_F1: 0.9874\n",
            "Epoch 00055: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0393 - acc: 0.9874 - F1: 0.9745 - Weighted_F1: 0.9875 - val_loss: 1.3177 - val_acc: 0.8132 - val_F1: 0.7148 - val_Weighted_F1: 0.8150\n",
            "Epoch 56/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9873 - F1: 0.9741 - Weighted_F1: 0.9873\n",
            "Epoch 00056: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0385 - acc: 0.9872 - F1: 0.9741 - Weighted_F1: 0.9873 - val_loss: 1.2845 - val_acc: 0.8177 - val_F1: 0.7164 - val_Weighted_F1: 0.8193\n",
            "Epoch 57/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9891 - F1: 0.9772 - Weighted_F1: 0.9891\n",
            "Epoch 00057: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0340 - acc: 0.9891 - F1: 0.9773 - Weighted_F1: 0.9891 - val_loss: 1.2984 - val_acc: 0.8261 - val_F1: 0.7292 - val_Weighted_F1: 0.8256\n",
            "Epoch 58/63\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0353 - acc: 0.9883 - F1: 0.9768 - Weighted_F1: 0.9884\n",
            "Epoch 00058: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0353 - acc: 0.9883 - F1: 0.9768 - Weighted_F1: 0.9884 - val_loss: 1.3046 - val_acc: 0.8189 - val_F1: 0.7152 - val_Weighted_F1: 0.8199\n",
            "Epoch 59/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9882 - F1: 0.9757 - Weighted_F1: 0.9882\n",
            "Epoch 00059: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 0.0359 - acc: 0.9881 - F1: 0.9755 - Weighted_F1: 0.9882 - val_loss: 1.2999 - val_acc: 0.8192 - val_F1: 0.7188 - val_Weighted_F1: 0.8203\n",
            "Epoch 60/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9869 - F1: 0.9719 - Weighted_F1: 0.9869\n",
            "Epoch 00060: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0427 - acc: 0.9869 - F1: 0.9719 - Weighted_F1: 0.9869 - val_loss: 1.2558 - val_acc: 0.8191 - val_F1: 0.7125 - val_Weighted_F1: 0.8188\n",
            "Epoch 61/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9881 - F1: 0.9764 - Weighted_F1: 0.9882\n",
            "Epoch 00061: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 0.0373 - acc: 0.9881 - F1: 0.9764 - Weighted_F1: 0.9882 - val_loss: 1.2589 - val_acc: 0.8144 - val_F1: 0.7161 - val_Weighted_F1: 0.8161\n",
            "Epoch 62/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9892 - F1: 0.9771 - Weighted_F1: 0.9892\n",
            "Epoch 00062: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0330 - acc: 0.9892 - F1: 0.9771 - Weighted_F1: 0.9892 - val_loss: 1.3111 - val_acc: 0.8207 - val_F1: 0.7226 - val_Weighted_F1: 0.8223\n",
            "Epoch 63/63\n",
            "91/92 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9892 - F1: 0.9770 - Weighted_F1: 0.9893\n",
            "Epoch 00063: val_loss did not improve from 0.49500\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 0.0324 - acc: 0.9892 - F1: 0.9767 - Weighted_F1: 0.9892 - val_loss: 1.3518 - val_acc: 0.8264 - val_F1: 0.7268 - val_Weighted_F1: 0.8254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-10-01T08:55:28.988339Z",
          "iopub.status.busy": "2021-10-01T08:55:28.988128Z",
          "iopub.status.idle": "2021-10-01T08:55:30.322713Z",
          "shell.execute_reply": "2021-10-01T08:55:30.322032Z",
          "shell.execute_reply.started": "2021-10-01T08:55:28.988313Z"
        },
        "id": "A99J2oAXbwjd",
        "tags": [],
        "outputId": "4d80cefd-21b3-48f3-c758-bd6fea1dffea"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3320 - acc: 0.8260 - F1: 0.7215 - Weighted_F1: 0.8245\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.332003116607666,\n",
              " 0.8260087966918945,\n",
              " array([0.8973942 , 0.81584704, 0.8965127 , 0.8388306 , 0.44444442,\n",
              "        0.5888325 , 0.568779  ], dtype=float32),\n",
              " 0.8244813680648804]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:55:30.324137Z",
          "iopub.status.busy": "2021-10-01T08:55:30.323766Z",
          "iopub.status.idle": "2021-10-01T08:55:32.631114Z",
          "shell.execute_reply": "2021-10-01T08:55:32.630324Z",
          "shell.execute_reply.started": "2021-10-01T08:55:30.324109Z"
        },
        "tags": [],
        "id": "eIKR_FWeEZAk"
      },
      "source": [
        "model = load_model(\"best_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-01T08:55:32.632465Z",
          "iopub.status.busy": "2021-10-01T08:55:32.632247Z",
          "iopub.status.idle": "2021-10-01T08:55:41.793595Z",
          "shell.execute_reply": "2021-10-01T08:55:41.792874Z",
          "shell.execute_reply.started": "2021-10-01T08:55:32.632440Z"
        },
        "tags": [],
        "id": "q81Uj7zwEZAl",
        "outputId": "c4c465cf-8d69-447c-84de-3eb68ebe13b1"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "192/192 [==============================] - 1s 7ms/step - loss: 0.5143 - acc: 0.8407 - F1: 0.7181 - Weighted_F1: 0.8357\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5143125057220459,\n",
              " 0.840712308883667,\n",
              " array([0.90235686, 0.8412578 , 0.90832156, 0.84725535, 0.5245902 ,\n",
              "        0.48044693, 0.5223881 ], dtype=float32),\n",
              " 0.8356819152832031]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}
